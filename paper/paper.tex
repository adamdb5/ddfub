\documentclass[a4paper, 11pt]{report}
\usepackage[margin=1in]{geometry}
\usepackage{listings}
\usepackage[strings]{underscore}
\usepackage{dirtytalk}
\usepackage{xcolor}
\usepackage{multicol}
\usepackage{multirow}
\usepackage{graphicx}
\usepackage{pdfpages}
\usepackage{appendix}
\usepackage{float}
\usepackage{booktabs}
\usepackage{hyperref}
\usepackage[acronym,toc]{glossaries}

\definecolor{comment}{RGB}{0,128,0} % dark green
\definecolor{string}{RGB}{255,0,0}  % red
\definecolor{keyword}{RGB}{0,0,255} % blue
\graphicspath{ {./images/} }

\loadglsentries{glossary}
\makeglossaries

\lstdefinestyle{c}{
	commentstyle=\color{comment},
	stringstyle=\color{string},
	keywordstyle=\color{keyword},
	basicstyle=\footnotesize\ttfamily,
	numbers=left,
	numberstyle=\tiny,
	numbersep=5pt,
	frame=lines,
	breaklines=true,
	prebreak=\raisebox{0ex}[0ex][0ex]{\ensuremath{\hookleftarrow}},
	showstringspaces=false,
	upquote=true,
	tabsize=2,
}

%%%%%%%%%%%%%%%%%%
% TITLE
%%%%%%%%%%%%%%%%%%
\iffalse
\title{\Huge{{Using Blockchain to Create a Decentralised Security Model for Distributed Systems}}}
\date{May 2021}
\author{
\Large{Adam David Bruce} \\ \texttt{\href{mailto:a.bruce3@newcastle.ac.uk}{a.bruce3@newcastle.ac.uk}}}
\begin{document}
\maketitle
\fi

\begin{document}

\begin{center}
\thispagestyle{empty}
\Huge{{Using Blockchain to Create a Decentralised Security Model for Distributed Systems}} \\
\vspace{1.0cm}
\LARGE{Adam David Bruce} \\ 
\vspace{1.0cm}
\LARGE{May 2021} \\
\vspace{13.0cm}
\LARGE{Computer Science (Security and Resilience)} \\
\vspace{1.0cm}
\LARGE{Supervisor: Dr John Mace} \\
\vspace{1.0cm}
\LARGE{{Word count: 14,998}}
\end{center}

\newpage
\section*{Declaration}
\say{I declare that this dissertation represents my own work except where otherwise stated.}


\newpage

%%%%%%%%%%%%%%%%%%
% ABSTRACT
%%%%%%%%%%%%%%%%%%
\begin{abstract}
Network security has, and always will be one of the greatest concerns for universities and other educational institutions. The 2020 cyberattacks throughout the COVID-19 pandemic highlighted both the importance of cybersecurity in UK universities, but also the lack of modern security infrastructure deployed across campuses. This literature aims to provide a method for universities to share information on potential, or ongoing cyberattacks to other universities via a trustworthy channel, capable of operating independently from other security measures. This is achieved by creating \gls{middleware} capable of running on existing devices on each campus that uses \gls{blockchain} to establish a decentralised trust mechanism. We explore a number of methods to achieve this including examining existing technologies as well as designing and implementing our own. A thorough analysis of our implementation is provided and we conclude by suggesting a number of future improvements that could be made to improve both the efficiency and effectiveness of such a system.
\end{abstract}

%%%%%%%%%%%%%%%%%%
% TABLE OF CONTENTS, FIGURES and TABLES
%%%%%%%%%%%%%%%%%%
\tableofcontents
\listoffigures
\listoftables

\newpage

%%%%%%%%%%%%%%%%%%
% INTRODUCTION
%%%%%%%%%%%%%%%%%%
\chapter{Introduction}
\section{COVID-19 and Cyberattacks}
In the summer of 2020, during the midst of the COVID-19 pandemic, universities and research institutions worldwide were working hard to understand the structure of the virus and develop a vaccine in an attempt to return to normality. However, whereas some countries were making fast progress in understanding the virus, others were falling behind, and the virus began to put a strain on healthcare, and increasing critique on governments. In order to keep up with the nations at the forefront of vaccine development, nations turned to state-sponsored cyberattacks in order to both hinder nations, and also obtain research and information about other countries' vaccine efforts. One such example was the threat group 'Cozy Bear', formally known as \acrfull{APT} 29. \acrshort{APT}29 used a number of tools to target various organisations involved in COVID-19 vaccine development in Canada, the United States and the United Kingdom. The \acrfull{NCSC} believe that the intention was highly likely stealing information and intellectual property relating to the vaccine \cite{APT29}.

In addition to the mortality of COVID-19, the virus also caused a number of economic issues across a number of nations. Global stock markets lost \$6 trillion in value over size days from 23 to 28 February \cite{covspill}. This gave private companies no other choice than to make large volumes of staff redundant, which increased job insecurity causing many people to become redundant, and in nations without suitable support or benefits, attackers turned to cybercrime for financial gain. These attacks represented the majority of cyberattacks aimed at both universities and the general public. A study of cyber-crime throughout the COVID-19 pandemic determined that 34\% of attacks directly involved financial fraud with a number of attack surfaces used, the majority being \gls{phishing}, \gls{smishing} and \gls{malware}~\cite{diffattack}.

University attacks became a frequent headline in the UK as universities suffered attacks from different threat actors. A number of threat actors launched attacks against multiple universities in the hope to find a vulnerability in at least one. One such attack was aimed at both Newcastle University and Northumbria University, two universities in extremely close proximity \cite{newhack,norhack}. The attack crippled both Newcastle University and Northumbria University, however the attackers only managed to exfiltrate data from Newcastle University. Why was the attack successful on both occasions? Why wasn't knowledge of the attack shared? 

One reason is that currently, there is no reliable or automated system in place to share this information. Such a system is what this paper will aim to create. 

\section{Distributed Systems} \label{distributed}
A distributed system is defined by Tanenbaum and van Steen as a \say{collection of independent computers that appears to its users as a single coherent system} \cite{tanenbaumdist}. Such systems are commonplace in peer-to-peer computing and sensor networks where each systems contributes some data via transactions to the system. A distributed system therefore should be autonomous and to the user, should appear as though they are interacting with a single system. Furthermore users and applications should be able to interact with the distributed system in a consistent and uniform way, regardless of where and when system interaction takes place. This requires a common interface provided by a \gls{stub} which is used to bridge the gap between a programming language or protocol and the distributed system. This \gls{stub} hides the differences in machine architecture and communication between the computer and the distributed system. The use of \gls{stub}s creates a new software layer, known as \gls{middleware} which runs on an \acrfull{OS} and exposes distributed functions to higher-level applications and users.

\begin{center}
	\begin{figure}[H]
		\includegraphics[width=\textwidth,keepaspectratio]{TanenbaumDistributed}
		\caption{A Distributed System visualised as \gls{middleware} \cite{tanenbaumdist}} 
		\label{fig:middleware}
	\end{figure}
\end{center}

\section{Decentralised Systems}
Reed defines a decentralised computer system as a computer system that \say{involves separation of the computers in the system by physical distance, by boundaries of administrative responsibility for individual computers and their applications, and by firewalls} \cite{namingSyncDec}. Reed suggests that for a computer system to be decentralised, it must be separated by both physical distance and administrative responsibility, such that no single body administrates the system. One of the most well-known examples of decentralisation is \gls{cryptocurrency}, a currency which takes no physical form, but instead exists entirely digitally. If cryptocurrency were to be governed by a central body, nefarious transactions could be used to launder money. Using a decentralised system ensures the transaction can only take place if all nodes within the system are in consensus that the transaction is genuine.

\section{Blockchain}
Nofer et al. define \gls{blockchain}s as \say{data sets which are composed of a chain of data packages (blocks) where a block comprises multiple transactions. The \gls{blockchain} is extended by each additional block and hence represents a complete \gls{ledger} of the transaction history.} \cite{blockchain}. Nofer et al. describe the basic fundamentals of a \gls{blockchain}, which is that numerous blocks of transactions contribute to a larger chain. This chain is never controlled by a single body, instead a copy of the chain is stored at each node within a system, making \gls{blockchain} a popular candidate for controlling transactions over a decentralised computer system. Hence, \gls{blockchain} is the foundation for the vast majority of cryptocurrencies including Bitcoin\cite{bitcoin} and Ethereum\cite{ethereum}. One of the key aspects of \gls{blockchain} is the use of cryptographic \gls{hashing} algorithms, these algorithms represent a block as a fixed-length string. For a block to be added to the chain, it must contain the hash of the previous block.

\begin{center}
	\begin{figure}[H]
		\includegraphics[width=\textwidth,keepaspectratio]{NoferBlock}
		\caption{An example of a \gls{blockchain} \cite{blockchain}} 
		\label{fig:blockchain}
	\end{figure}
\end{center}

%%%%%%%%%%%%%%%%%%
% AIMS AND OBJECTIVES
%%%%%%%%%%%%%%%%%%
\section{Aims and Objectives} \label{aim}
The original aim for this project was to design and create a decentralised firewall that could communicate knowledge of cyberattacks aimed at universities in real-time, allowing other universities to protect themselves from the same attacks. This system would be distributed, and hence must conform to the previous description of a distributed system in section \ref{distributed}. Following an extensive amount of background reading, there appeared to be no existing implementation or design of such a system which inspired the alteration of the aim to instead focus on designing a protocol and implementing a \gls{stub} to demonstrate the protocol's effectiveness. This project will therefore not be implementing a firewall, but instead a system to coordinate firewalls, allowing cyberattacks to be prevented without use of additional systems or requiring human involvement. Further research determined that \gls{blockchain} was the best choice for the underlying structure for such a protocol, and so this final change shaped the current aim for this project: \textbf{Using Blockchain to Create a Decentralised Security Model for Distributed Systems}.\\\\

The following objectives provide an outline for what this project hopes to achieve:

\begin{enumerate}
    \item Evaluate the effectiveness of existing distributed security mechanisms.
    \item Investigate methods of establishing connections and synchronising computers within distributed systems.
    \item Understand the structure of \gls{blockchain}s and adapt them for firewall rules.
    \item Implement and test relevant resilience, fault tolerance and security mechanisms.
    \item Compare the use of decentralised security mechanisms.
\end{enumerate}

\section{This Document}
The following chapter will explain the background research conducted before starting this project. Once the necessary research has been documented, the design, implementation and testing of this project will be detailed. Finally, at the end of this document, an evaluation will be conducted followed by a conclusion to identify the success of this project and outline future work.

%%%%%%%%%%%%%%%%%%
% BACKGROUND
%%%%%%%%%%%%%%%%%%
\chapter{Background}
This section details the essential background research for this project. It looks at distributed systems, remote procedure calls, decentralised systems, blockchain, security, firewalls, fault tolerance, computer networks and inter-process communication.

\section{Distributed Systems} \label{dist}
The primary reference used for distributed systems was Tanenbaum and van Steen's \say{Distributed Systems: Principles and Paradigms}\cite{tanenbaumdist}, who's literature provides an in-depth explanation from the fundamental theory of distributed systems to the design and implementation of such systems. Key details that were taken from this publication are detailed below. In general, this book covered the essential components of creating a distributed system, however much of the detail with regards to client-server interactions was not applicable to this project due to it's decentralised nature. Furthermore, a large portion of the book was not of interest to this project as it focuses on distributed processing, which only comprises a small element of this project, hence a large volume of information regarding implementation of processing was not useful.

\subsection{Architecture}
Tanenbaum and van Steen cover many aspects of a distributed system's architecture spanning network, software and physical architecture. This project will implement a decentralised, peer-to-peer network architecture, which will be discussed in detail in section \ref{decentrailsed}. The software used will consist primary of \gls{stub}s, which are used to hide the differences in machine architecture and communication between the computer and the distributed system. The combined use of \gls{stub}s creates a new software layer, known as \gls{middleware} which provides a common interface between a client application, and the distributed system. Creating this layer enables applications to communicate via an application-level protocol, which is independent from the protocol spoken by the \gls{middleware}.

\begin{figure}[H]
\centering
\includegraphics[height=5cm,keepaspectratio]{appl_layer_proto}
\caption{Application layer protocol running over \gls{middleware} \cite{tanenbaumdist}} 
\label{fig:middlewarelayers}
\end{figure}

With regards to physical architecture, Tanenbaum and van Steen discuss a number of approaches to client-server architectures, however due to the decentralised nature of this project, non of Tanenbaum and van Steen's classifications apply. 

\subsection{Remote Procedure Calls (RPC)}
Tanenbaum and van Steen introduce the concept of a \acrfull{RPC}. \acrshort{RPC}s are used to execute some action on a remote node within a distributed system.  Tanenbaum and van Steen provide a concise breakdown of the steps required to execute an \acrshort{RPC}:

\begin{enumerate}
    \item The client procedure calls the client \gls{stub} in the normal way.
    \item The client \gls{stub} builds a message and calls the local \acrfull{OS}.
    \item The client \acrshort{OS} sends the message to the remote \acrshort{OS}.
    \item The remote \acrshort{OS} gives the message to the server \gls{stub}.
    \item The server \gls{stub} unpacks the parameters and calls the server.
    \item The server does the work and returns the result to the \gls{stub}.
    \item The server \gls{stub} packs it in a message and calls it's local \acrshort{OS}.
    \item The server's \acrshort{OS} send the message to the client's acrshort{OS}.
    \item The client's \acrshort{OS} sends the message to the client \gls{stub}.
    \item The \gls{stub} unpacks the result and returns to the client.
\end{enumerate}

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth,keepaspectratio]{rpc}
\caption{A breakdown of a \acrshort{RPC} \cite{tanenbaumdist}} 
\label{fig:rpc}
\end{figure}

\section{Decentralised Systems} \label{decentrailsed}
Gray's \say{An Approach to Decentralized Computer Systems} \cite{decentralised} provided the basis for the decentralisation aspect of this project. Gray summarises the advantages of using decentralised systems, a number of which support the argument for using a decentralised topology in this project. The advantages which are relevant to this project are documented below.

\begin{itemize}
    \item \textbf{Capacity}: A decentralised system can support a large number of devices.
    \item \textbf{Response Time}: Having devices in close proximity can reduce response times.
    \item \textbf{Availability}: A failure is likely to be limited to a single site, allowing the rest of the system to continue normal operation.
    \item \textbf{Security}: Removing the central controller in a traditional distributed system removes the risk of an attack compromising the whole system.
\end{itemize}

Gray's article also looks at how decentralised systems should be designed including data types, network protocols and transactions. There are a number of similarities between Tanenbaum and van Steen's \acrshort{RPC}s and the structure Gray proposes for decentralised transactions. For this project however, the finer details proposed by Gray's system are not relevant as the literature uses a large number of examples base heavily on financial transactions, which contain a number of additional complexities over the transactions used within this project.


\section{Blockchain}
The primary reference used for \gls{blockchain} was Nofer et al.'s \say{Blockchain}\cite{blockchain}. Nofer et al. provide a high level overview of \gls{blockchain}, focusing primarily on the structure and implementation, with some consideration of the current applications of \gls{blockchain} in both financial and non-financial settings. Although concise, this publication provides a valuable summary of the essential components of blocks in order to create a ledger which can accurately trace transactions. Although not essential for this project, Nofer et al. additionally discuss how \gls{blockchain} can be implemented into smart contracts. In general, this literature was useful in providing a baseline for the structure of blocks within a \gls{blockchain}, and clearly explained the purpose of each field within the block, which allowed informed decisions to be made in regard to the structure of blocks used in this project. 

\begin{center}
	\begin{figure}[H]
		\includegraphics[width=\textwidth,keepaspectratio]{NoferBlock}
		\caption{An example of a \gls{blockchain} \cite{blockchain}} 
		\label{fig:blockchain2}
	\end{figure}
\end{center}

\section{Distributed Security}
The primary reference used for distributed security was Rivest and Lampson's \say{SDSI - A Simple Distributed Security Infrastructure} \cite{sdsi}. This publication provides an in-depth explanation of how a public-key infrastructure can be used in conjunction with access control lists to create a distributed security infrastructure. The majority of the literature within this publication is focused on creating and issuing certificates, something that is not relevant for this project, however Rivest and Lampson did provide clear requirements over the data structures within such a system. Rivest and Lampson implement a message system similar to that of Tanenbaum and van Steen's in section \ref{dist}. The message system proposed by Rivest and Lampson contains only a type and dictionary of attributes.

\begin{figure}[H]
\centering
\includegraphics[height=2cm,keepaspectratio]{distmsg}
\caption{Message format for the SDSI Model \cite{sdsi}} 
\label{fig:sdsimessage}
\end{figure}

Additionally, Rivest and Lampson detail the concept of objects, which are defined by a type. This type is expressed in the form 

\begin{center} 
\texttt{protocol-name.message-type}
\end{center}

\section{Firewalls and Firewall Rules}
Al-Shaer and Hazem provide a detailed explanation of how firewall policies should be modelled and managed in \say{Modeling and Management of Firewall Policies} \cite{firewall}. This article explores methods of modelling policies and rules and provides a deep analysis of how those rules are interpreted by a firewall. The most relevant discussion within this literature is the structure of a firewall policy which is defined by Al-Shaer and Hazem as a set of rules, which act as records, with the following seven fields:

\begin{itemize}
    \item \textbf{Order}: The priority of a rule.
    \item \textbf{Protocol}: Either \acrfull{TCP} or \acrfull{UDP}.
    \item \textbf{Source IP}: The source IP address.
    \item \textbf{Source Port}: The source port.
    \item \textbf{Destination IP}: The destination IP address.
    \item \textbf{Destination Port}: The destination port.
    \item \textbf{Action}: The action the firewall should take (e.g. ACCEPT, DENY).
\end{itemize}

In regards to this project, there was little other relevant content in the literature. Following the change in this project's aim detailed in section \ref{aim}, this project was no longer concerned with the implementation of a firewall or the interpretation of firewall rules as this project was modified to manage communication of firewall rules, not the implementation of firewalls, which deemed the vast majority of Al-Shaer and Hazem's publication irrelevant.

Additional background information with regards to how firewalls are integrated into infrastructure came from Dulaney and Eastton's \say{CompTIA Security+ Study Guide: Exam SY0-501} \cite{comptiaSec}. Dulaney and Eastton's study guide covers a large number of aspects associated with cyber security, including technological, physical and psychological mitigations. With regards to firewalls, this publication details how the placement of firewalls can be used to form a \acrfull{DMZ}, which is a common network layout used by universities, as it permits certain areas of the network to be accessible from outside the local network.

\begin{figure}[H]
\centering
\includegraphics[height=10cm,keepaspectratio]{DMZ}
\caption{Using a firewall to create a \acrshort{DMZ}}
\label{fig:dmz}
\end{figure}

This information provided a strong understanding into where this project would fit in a standard network model. This publication also covered firewalls, however the information provided was not as detailed as that from Al-Shaer and Hazem, and hence no other aspects of this book were used.

\section{Fault Tolerance}
The primary reference for fault tolerance was Guerraoui and Schiper's \say{Fault-Tolerance by Replication in Distributed Systems}\cite{faulttol}. This literature details how replication can be used to provide fault tolerance in a distributed system in addition to ensuring consistency is maintained.  A number of backup techniques are discussed however the technique that is best suited for this project is primary backup replication. Primary backup replication consists of a client invoking an operation which is the applied to the primary data, and then cascaded to a number of additional backups.

\begin{figure}[H]
\centering
\includegraphics[height=5cm,keepaspectratio]{primback}
\caption{Primary backup technique \cite{faulttol}} 
\label{fig:backup}
\end{figure}

Guerraoui and Schiper continue to discuss methods of detecting faults and appropriate ways to deal with them. The methods covered however require a much greater level of control than that achievable by a single application running on a standard \acrshort{OS}, and hence are not applicable to this project.

\section{Computer Networks}
The primary reference for computer networks was Lammle's book \say{CompTIA Network+ Study Guide: Exam N10-007} \cite{comptiaNet}. Lammle's study guide covers a wide range of aspects associated with computer networks including physical implementations, subnets, security and protocols. Two sections which are relevant to this project are network layer protocols (\acrshort{TCP} and \acrshort{UDP}), and network topologies. Lammle provides a comprehensive explanation of the differences between \acrfull{TCP} and \acrfull{UDP}, however the difference that is most relevant to this project is \acrshort{TCP}'s requirement for a connection to be established prior to transmission. The book explains how establishing a \acrshort{TCP} connection takes additional time and blocks the port whilst attempting to establish a connection, which prevents any other connection from being made from that port. This is not ideal for a decentralised system as messages will be sent on an ad-hoc basis, with strict time constraints, and therefore \acrshort{UDP} will be more suitable for this project.

With regards to network topologies, Lammle details seven approaches: bus, star, ring, mesh, point-to-point, point-to-multipoint and hybrid. In order to create a truly decentralised distributed system, the mesh topology is best suited to this project. In a mesh topology, each device is connected to every other device, which provides the highest level of redundancy possible, as if one device were to crash, or a cable be disconnected, communication can continue via the other devices.

\begin{figure}[H]
\centering
\includegraphics[height=5cm,keepaspectratio]{mesh}
\caption{Mesh Topology} 
\label{fig:mesh}
\end{figure}

\section{Inter-Process Communication (IPC)}
Tanenbaum and Woodhull provide an extremely detailed breakdown of their UNIX based operating system in \say{Operating systems: Design and Implementation} \cite{operatingsystems}. This book covers all aspects of an \acrshort{OS}, providing insightful explanations of the decisions made at every step in the design process. As this project is designed to run as an application, many of the details covered in this publication are irrelevant, however Tanenbaum and Woodhull cover one essential aspect of this project: \acrfull{IPC}. \acrshort{IPC} is a function within many \acrlong{OS}s which enables multiple processes to communicate by passing messages to each other. \acrshort{IPC} will be the technique used to interact with the distributed system, as a client process will use \acrshort{IPC} to issue commands to the \gls{stub}. \\\\

The background research has identified how this project can utilise all of the mentioned technologies, along with a brief analysis regarding the relevance of each technology to this project.

\chapter{Design}

This section will look at how the project was designed from the ground up to include the relevant features to meet the aim and objectives. The section covers the logical design of the system, protocols and structures used within the system.

\section{System Architecture}
The implementation of the model proposed in this paper will be compiled into one single executable binary, but will interface with a number of external libraries and the \acrshort{OS} via system calls. The stub will primarily communicate with the \acrshort{OS} in order to establish sockets and bind them to the desired ports, the framework will then communicate with the \acrfull{NIC} to obtain it's assigned \acrfull{IP} address. Whenever a new block is created or received, OpenSSL's libcrypto library \cite{libcrypto} will be used to generate or validate the block's hash. This interaction is visualised in the following component diagram.

\begin{figure}[H]
\centering
\includegraphics[height=8cm,keepaspectratio]{componentdiagram}
\caption{System Component Diagram} 
\label{fig:comp}
\end{figure}

\section{Data Structures}
The system uses two primary structures for storing data within the system, these are used for storing firewall rules and blocks.

\subsection{Firewall Rule} \label{rule}
The system supports five different actions that can be applied to a firewall rule: allow, deny, bypass, force allow and log.  These actions are supported by the distributed system but firewall software remains free to interpret these actions freely, which ensures consistency can be achieved despite different firewall vendors.
The firewall rule structure comprises of the following:

\begin{table}[H]
\centering
\begin{tabular}{ |c|c|c|c| } 
\hline
Field Name & Data Type & Size (Bytes) \\
\hline
source_addr & Character Array & 15 \\
source_port & Unsigned Integer & 2 \\
dest_addr & Character Array & 15 \\
dest_port & Unsigned Integer & 2 \\
action & FirewallAction & 1 \\
\hline
\end{tabular}
\caption{The Structure of a Firewall Rule}
\label{tab:rulestr}
\end{table}

This structure supports the standard model for firewall policies, supporting categorisation by the source address, source port, destination address and destination port. Each rule is then given an associated action.

\subsection{Firewall Block} \label{firewallblock}
Firewall blocks are used to create the chain of firewall rules within the system. These are comprised of the following fields:

\begin{table}[H]
\centering
\begin{tabular}{ |c|c|c|c| } 
\hline
Field Name & Data Type & Size (Bytes) \\
\hline
last_hash & Unsigned Char Array & Dependent on Hash Algorithm \\ 
author & Character Array & 15 \\
rule & FirewallRule & Dependent on machine architecture \\
next & FirewallBlock Pointer & Dependent on machine architecture \\
\hline
\end{tabular}
\caption{The Structure of a Firewall Block}
\label{tab:firewallblock}
\end{table}

The structure holds the last block hash in order to verify that the block has been validated and fits onto the chain. In addition to the last block hash, the structure includes the author of the block, which enables an audit to verify that the block was submitted by a reputable source. The structure contains a firewall rule which has been described previously in section \ref{rule}. Finally, the structure contains a pointer to another block, this field is used to join the blocks into a chain via a linked list. When a block is appended to the chain, this field will be null, however once the next block is added to the chain, this field will point to the new block.

\section{Message Structures}
The system uses two different message passing mechanisms, these being via the network for distributed transactions, and via \acrshort{IPC} for client - stub communication. Each message type follows a particular structure which is discussed below.

\subsection{Network} \label{netstruct}
For communications within the distributed system, three different message types are used: advertisement, consensus and rule. Furthermore, each message contains a subtype which is either a broadcast or an acknowledgement. All message types contain a set of common fields, which are detailed below.

\begin{table}[H]
\centering
\begin{tabular}{ |c|c|c|c| } 
\hline
Field Name & Data Type & Size (Bytes) \\
\hline
type & MessageType & 1 \\ 
subtype & MessageSubType & 1 \\ 
hops & Unsigned Integer & 1 \\ 
source_addr & Character Array & 15 \\
target_addr & Character Array & 15 \\
next_addr & Character Array & 15 \\
\hline
\end{tabular}
\caption{Common Fields in all Network Messages}
\label{tab:common}
\end{table}

The type field holds an enum which is called MessageType and contains three values: advertisement, consensus and rule. Similarly the subtype field holds an enum that contains two values: broadcast and acknowledgement. Broadcast messages are used to advertise a new device, request consensus and distribute new a firewall transaction, whereas acknowledgements are used to provide a response, such as acknowledging the new device and providing consensus for a proposed transaction. As the system is decentralised, messages are not sent directly to remote hosts as there may be devices on the network that another device is unaware of, which would result in unsynchronised \gls{blockchain}s. The use of a hop count allows the number of times a message can be sent around the network to be limited, essential to prevent older messages from clogging up the system. The last three fields contain addresses of devices. It may appear unnecessary to provide these values as the messages are wrapped in an \acrshort{IP} packet which already contains these values. These are necessary as when messages are relayed, the \acrshort{IP} packet contains the address of the most recent sender, overwriting the original information. The source address contains the address of the origin device, the target address contains the address of the final destination, and the next address contains the address of the next device to propagate the message to.

\subsubsection{Advertisement Messages}
The advertisement message is used to advertise the presence of a new device within the distributed system. This message contains no additional fields than those described in table \ref{tab:common}. When the advertisement message subtype is broadcast, the source address is set to the new device's \acrshort{IP} address. At least one host must be known to advertise on the network, and this host's address will be placed into the next address field. The target address field is not used for broadcasts as there is no specific target that the message should be sent to. Once a node receives an advertisement broadcast, it will check whether that host is already known, if so, the message is ignored, and propagated, otherwise if the host is not yet known, the node first adds the new device to its list of known hosts, and then propagates the message. When the acknowledgement is sent, the target address is set to the address of the new device, which ensures that any other nodes which may have also advertised do not interpret the acknowledgement as regarding their broadcast. Once the acknowledgement arrives at the new device, the node adds the host which sent the ack, but does not propagate the message.

\subsubsection{Consensus Messages}
The consensus message is used when a client or firewall submits a new firewall rule to the \gls{stub} via \acrshort{IPC}. This message contains one additional field which holds the hash of the last block. When a node proposes a new firewall rule, it must first submit the hash of it's last block, which is sent to all known hosts. On receipt of a consensus broadcast, the node calculates the hash of the last block on it's chain, and if it matches the hash sent in the message it sends an ack, and appends the origin node's address to a list of pending rules. The node then forwards the message to all known hosts. After broadcasting the message, the origin host resets a counter, which is incremented every time it receives an ack from one of it's known hosts. If this counter reaches atleast half of it's known hosts in some bounded time, it is deemed to have obtained consensus and may now distribute the new firewall rule.

\begin{table}[H]
\centering
\begin{tabular}{ |c|c|c|c| } 
\hline
Field Name & Data Type & Size (Bytes) \\
\hline
last_block_hash & Unsigned Char Array & Dependent on Hash Algorithm \\ 
\hline
\end{tabular}
\caption{Additional Fields in a Consensus Message}
\label{tab:consensus}
\end{table}

\subsubsection{Rule Messages}
The rule message is used to distribute a new firewall rule once a node has achieved consensus. Only the broadcast subtype is used for rule messages, as waiting for acknowledgements could halt the system at the time of an attack, which would prevent the node from responding to other attacks. Upon receiving a rule broadcast the node will check to see if has previously approved the transaction by looking up the rule's origin in its list of pending rules. If the origin exists in the pending rules then the new block will be added to the chain, including its author and the last hash, then propagated to all of the node's known hosts.

\begin{table}[H]
\centering
\begin{tabular}{ |c|c|c|c| } 
\hline
Field Name & Data Type & Size (Bytes) \\
\hline
rule & FirewallRule & Dependent on machine architecture \\ 
\hline
\end{tabular}
\caption{Additional Fields in a Rule Message}
\label{tab:rule}
\end{table}

\subsection{IPC}
There are four different types of \acrshort{IPC} message: rule, enable, disable, shutdown. The rule type is intended to be sent by a firewall, and contains a new firewall rule to be submitted to the distributed system. The enable and disable message types simply control the status of the stub, if it is believed that a host on the network may be malfunctioning (i.e. a firewall is sending bogus rules), it can be disabled and then re-enabled once the fault is fixed. Finally the shutdown message is used to properly terminate the \gls{stub}. Upon receiving the shutdown message, all sockets will be closed, the \acrshort{IPC} tunnel will be destroyed and the application will wait for all threads to terminate before exiting.
To ensure messages can be parsed correctly, all of these message types follow the same structure, and the rule field is simply disregarded for all non-rule messages.

\begin{table}[H]
\centering
\begin{tabular}{ |c|c|c|c| } 
\hline
Field Name & Data Type & Size (Bytes) \\
\hline
message_type & IPCMessageType & 1 \\
rule & FirewallRule & Dependent on machine architecture \\
\hline
\end{tabular}
\caption{Structure of \acrshort{IPC} Messages}
\label{tab:ipc}
\end{table}
 
\section{ACR Protocol}
As described in section \ref{netstruct}, the system supports three message types: advertisement, consensus and rule, which form the ACR protocol.

\subsection{Advertisement}
The advertisement message is sent at startup and is mutually exclusive from the other messages, as it is executed automatically and does not affect the consensus or rule transaction stages. The advertisement message is sent when the framework is executed. The framework will send an advertisement broadcast to all known hosts, each of which will relay the message to each of their known hosts, provided that the hop count has not yet been exceeded. Upon receiving an advertisement message, the host checks if the host is known, if not, it is added, and an acknowledgement is returned.

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth,keepaspectratio]{advertisement_seq}
\caption{Advertisement Sequence Diagram} 
\label{fig:advseq}
\end{figure}

\subsection{Consensus-Rule}
The consensus and rule messages are sent when a client or firewall sends an \acrshort{IPC} message to the local \gls{stub}. Upon receiving the rule, the \gls{stub} will marshal the parameters into a network message, which is then sent to all known hosts. When a node receives the consensus message, it will compare the hash in the message to the hash of the previous block on its chain, if the hashes match, the block is considered valid and an acknowledgement is returned. The broadcast is then forwarded to all of the hosts known by that node. When the origin node receives an acknowledgement, it will check if that host is known. If it is not, then it will not increment the ack count, as it would interfere with the consensus calculation, however it will still receive the rule, if consensus is achieved. The origin node will then wait for some timeout, after which it will test if a sufficient number of acknowledgements have been received in comparison to the number of known hosts. If this test passes (e.g. at least half of the known hosts must acknowledge), then a rule message is sent. No acknowledgements are sent upon receipt of a rule message, but nodes will continue to propagate the message until the hop limit is reached.

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth,keepaspectratio]{consensus_rule_seq}
\caption{Successful Consensus-Rule Sequence Diagram}
\label{fig:consruleseq}
\end{figure}

This section has provided the foundations for the software and protocol allowing an proof of concept to be implemented in the next chapter.

\chapter{Implementation}

This section will discuss the different technologies used within the system and how they were incorporated into this project. A detailed analysis is provided whenever a decision was made in regards to using different technologies, tools or languages. 

\section{Language}
The logic within this project could be achieved using a range of programming languages, however such a system needs to be reliable and fast, which narrows down the applicable languages. As cross compatibility is desirable, Java\cite{java} or Python\cite{python} may seem like the best options as Java executes entirely within the Java Virtual Machine (JVM)\cite{jvm} and Python is executed using an interpreter. Each of these technologies provide a suitable abstraction such that if the \acrshort{VM} or interpreter is supported by an \acrshort{OS}, it should work. The drawbacks associated with this are that a \acrshort{VM} or interpreter introduce a large memory overhead, something that is not desirable given this framework is intended to be implemented into edge devices, additionally, with such abstractions we lose both speed and control. Rust\cite{rust} is a modern language focused on performance and reliability, however its immaturity leaves a number of features missing or poorly implemented as it currently relies heavily on community submitted modules. One advantage of Rust however is its low memory footprint, and memory management, which enables small binary executables to be built, ideal for this project. 

The final two languages considered were C\cite{c} and C++\cite{cpp}. It may seem an obvious choice to use C++ over C, however for this project very few features of C++ would be useful, and would simply add additional steps in the program to bridge between \acrfull{POSIX} functions (implemented in C) and C++ types and syntax. One advantage that C has over C++ is its existing dominance in operating systems. Deemed the \textit{system programming language}, the Linux\cite{linux} and NetBSD\cite{netbsd} kernels are written in pure C, along with the vast majority of the FreeBSD\cite{freebsd} and Windows\cite{windows} kernels. This means that using C enables this project to be compiled into an operating system, such that the distributed system is automatically instantiated on boot in kernel space and cannot be stopped or interrupted by a malicious application or user. Furthermore, writing this project in C allows wrappers to be written for all other languages, C++ can be integrated with no changes, and modules can be written for most other languages including Java and Python.

\section{IPC}
In order to achieve cross-platform \acrshort{IPC}, different approaches were required for \acrfull{POSIX} compliant operating systems and Windows\cite{windows} operating systems. Each \acrshort{OS} type offers a number of \acrshort{IPC} methods, which are briefly discussed in the following sections.

The \gls{stub} provides the following abstractions for interfacing with native \acrshort{IPC}.\\\\

\begin{lstlisting}[language=c,style=c,caption=IPC API]
int init_ipc_server(void);
int init_ipc_client(void);
int connect_ipc(void);
int cleanup_ipc(void);
int send_ipc_message(IPCMessage *message);
int recv_ipc_message(IPCMessage *message);
\end{lstlisting}

\subsection{POSIX} \label{posixipc}
\acrshort{POSIX} systems provide four interfaces for \acrshort{IPC}: pipes, FIFO, message queues and sockets. Although pipes do allow processes to communicate, the primary purpose of pipes is to obtain the output of one command and pass this output into a second command, which is not suitable for our application. FIFO and message queues operate very similarly, whereby each method creates some file in the filesystem which can then be referenced by any process. FIFO is the predecessor to message queues, and hence different operating systems have varying implementations for FIFO, however as message queues are a \acrshort{POSIX} standard, all implementations provide the same interface, greatly simplifying the process of making this project cross compatible. For this reason, message queues were used for \acrshort{POSIX} \acrshort{IPC}. The final method is via UNIX sockets. The socket interface is primarily designed for networked communication, but also supports \acrshort{IPC}. Unfortunately, as sockets are intended for use in networks, some implementations still use the \acrshort{NIC} to communicate even locally, which slows down communication, and adds additional points of failure.

\begin{lstlisting}[language=c,style=c,caption=Creating the message queue on a POSIX OS]
mqueue = mq_open("/dfw", O_CREAT | O_RDWR, 0644, &attr);
\end{lstlisting}

\subsection{Windows}
Windows\cite{windows} offers three methods of \acrshort{IPC}: Anonymous Pipes, Named Pipes and sockets. Anonymous pipes allow half-duplex communication, which is not ideal for this project, as it is necessary for the client / firewall to send instructions to the \gls{stub}, and for the \gls{stub} to send messages back to the client. Furthermore, Hart\cite{windowsprog} explains the fundamental issue with anonymous pipes: they have no identifier associated with them, which creates a new problem of communicating the pipe handle to any clients wishing to connect. Named pipes are full-duplex, message oriented pipes than can operate locally or over a network. The difference between anonymous and named pipes is that a named pipe can be identified using a string which represents a file path, this enables both client and \gls{stub} to connect directly to the pipe. The final method is via sockets which act similarly to UNIX sockets, and hence have the same pitfalls as UNIX sockets mentioned in section \ref{posixipc}.\\

\begin{lstlisting}[language=c,style=c,caption=Creating the message queue on Windows]
mqueue = CreateNamedPipe(TEXT("\\\\.\\pipe\\dfw"),
                           PIPE_ACCESS_DUPLEX | FILE_FLAG_OVERLAPPED,
                           PIPE_TYPE_MESSAGE, 1, 0, 0, 0, NULL);
\end{lstlisting}

\section{Sockets}
Network sockets are the primary method allowing processes to communicate over a network, however similarly to \acrshort{IPC}, \acrshort{POSIX} and Windows systems provide slightly different socket interfaces. A numeric port is bound to the socket which enables the network stack to communicate with the socket, and hence the process. The main difference is that Windows requires the initialisation of the WinSock\cite{winsock} library. Thankfully other than the initialisation of WinSock, the rest of the interface provided by WinSock is very similar to the basis of \acrshort{POSIX} sockets, which are known as Berkeley sockets. This similarity means that only small modifications need to be made to the source code. After creating the socket, it is then bound to the numeric port. The default ports used for this project are 8070 and 8071.

The \gls{stub} provides the following abstractions for interfacing with native sockets.
\begin{lstlisting}[language=c,style=c,caption=Socket API]
int init_sockets(void);
int cleanup_sockets(void);
socket_t create_socket(void);
void close_socket(socket_t sock);
int bind_socket(socket_t sock, int port);
int send_to_socket(socket_t sock, void *message, size_t length, int flags,
                   struct sockaddr_in dest_addr);
int recv_from_socket(socket_t sock, void *buffer, size_t length, int flags);
\end{lstlisting}

\section{Network}
As the project is focussed on creating a distributed system, the vast majority of the implementation is based on networking. Thankfully, due to the previous abstractions created regarding sockets, the network implementation consists primarily of the business logic. The one major difference between the UNIX network stack, and the Windows network stack, is querying the \acrshort{OS} to retrieve information from \acrshort{NIC}s. Implementing this required an entirely different system for each operating system. On UNIX, the \texttt{getifaddrs} function was used, whereas on Windows, the \texttt{GetAdaptersAddresses} function was used.

The \gls{stub} provides the following abstractions for interfacing with the native network stack.
\begin{lstlisting}[language=c,style=c,caption=Network API]
int get_local_address(char *buffer);
int get_acks(void);
int reset_acks(void);
int set_ack(char *addr);
int load_hosts_from_file(const char *fname);
int save_hosts_to_file(const char *fname);
int add_host(char* addr);
int check_host_exists(char *addr);
int get_host_count(void);
int init_net(void);
int cleanup_net(void);
int send_to_host(char *ip_address, void *message, size_t length);
int send_advertisement_message(AdvertisementMessage *message);
int send_to_all_advertisement_message(AdvertisementMessage *message);
int recv_advertisement_message(void *buffer);
int recv_advertisement_broadcast(AdvertisementMessage *message);
int recv_advertisement_ack(AdvertisementMessage *message);
int send_consensus_message(ConsensusMessage *message);
int send_to_all_consensus_message(ConsensusMessage *message);
int recv_consensus_message(void *buffer);
int recv_consensus_broadcast(ConsensusMessage *message);
int recv_consensus_ack(ConsensusMessage *message);
int send_rule_message(RuleMessage *message);
int send_to_all_rule_message(RuleMessage *message);
int recv_rule_message(void *buffer);
int recv_rule_broadcast(RuleMessage *message);
int poll_message(void *buffer, size_t length);
\end{lstlisting}

\section{Multithreading}
In order for the \gls{stub} to be capable of consecutively sending and receiving messages over both the network, and via \acrshort{IPC}, the framework had to be multithreaded. Unsurprisingly, \acrshort{POSIX} and Windows use different thread models, which means there is no common threading interface. Thankfully, the \acrshort{POSIX} thread model has been ported to Windows in the form of the \acrshort{POSIX} Threads for Windows project\cite{pthread}. This allows the source code to be written identically for all operating systems, the only difference being that the Windows binary will be linked with the necessary Dynamic-Link Library (DLL).

\section{Blockchain}
Once the previous \acrshort{API}s had been created, the \gls{blockchain} aspect of the project could be implemented. As the structure of these blocks have already been discussed in section \ref{firewallblock}, this section will focus on how the functionality of this was implemented, primarily the \gls{hashing} of blocks.

\subsection{Hash Algorithms} 
The first decision that had to be made was which hash algorithm to implement. A wide range of hash algorithms are available, however the most popular three are Secure Hash Algorithm (SHA), MD5 and BLAKE. The SHA hash suite boasts a number of algorithms which are classed into four generations: SHA-0, SHA-1, SHA-2 and SHA-3. The SHA-0 and SHA-1 algorithms are the least secure, and are now deemed insecure as collisions have been found, which would enable a malicious block to contain the hash of a valid block. At the time of writing this, there are no known collisions for the SHA-2 or SHA-3 families. The MD5 hash algorithm is also insecure for the same reason as SHA-1 and is hence not appropriate for this project. The final algorithm family is BLAKE, which consists of three families: BLAKE, BLAKE2 and BLAKE3. There are no known collisions within any of the BLAKE hash families, however the BLAKE algorithm has not been tested for \gls{blockchain} applications, whereas the SHA family has. For this reason, this project will utilise the same hash algorithm as Bitcoin \cite{bitcoin}, SHA-256.

\begin{table}[H]
\centering
\begin{tabular}{ |c|c|c|c|c| } 
\hline
\multicolumn{2}{|c|}{Hash Algorithm} & Output Size & Collisions found? & Used By \\
\hline
\multicolumn{2}{|c|}{MD5} & 128 & Yes & None \\
\hline
\multicolumn{2}{|c|}{SHA-0} & 160 & Yes & None \\
\hline
\multicolumn{2}{|c|}{SHA-1} & 160 & Yes & None \\
\hline
\multirow{6}*{SHA-2} & SHA-224 & 224 & No & None \\
& SHA-256 & 256 & No & Bitcoin\cite{bitcoin}, Bitcoin Cash \\
& SHA-384 & 384 & No & None \\
& SHA-512 & 512 & No & None \\
& SHA-512/224 & 224 & No & None \\
& SHA-512/256 & 256 & No & None \\
\hline
\multirow{4}*{SHA-3} & SHA3-224 & 224 & No & None \\
& SHA3-256 & 256 & No & None \\
& SHA3-384 & 384 & No & None \\
& SHA3-512 & 512 & No & None \\
\hline
\multirow{4}*{BLAKE} & BLAKE-224 & 224 & No & None \\
& BLAKE-256 & 256 & No & None \\
& BLAKE-384 & 384 & No & None \\
& BLAKE-512 & 512 & No & None \\
\hline
\multirow{2}*{BLAKE2} & BLAKE2s & 256 & No & Nano\cite{nano} \\
& BLAKE2b & 512 & No & None \\
\hline
\multicolumn{2}{|c|}{BLAKE3} & Variable & No & None \\
\hline
\end{tabular}
\caption{Comparison of Hash Algorithms}
\label{tab:hashalgo}
\end{table}

\subsection{Hash Implementation}
When implementing the desired hash algorithm, there were two primary options, to implement the algorithm from scratch, or to use an existing library. If the algorithm was to be implemented from scratch, then the resulting application would require less dependencies and would overall result in a more self-contained binary. Using a library would result in one additional dependency, however the vast number of algorithms provided by most libraries would allow the entire \gls{blockchain} and protocol to be easily updated should a more secure algorithm be preferable. Furthermore, most libraries are thoroughly tested and well engineered to guarantee the most efficient operation and make sure the algorithms can handle every edge case. For this reason it was decided that an external library would be implemented, and a breakdown of the considered libraries is provided below \cite{hashlibcomp}.

\begin{table}[H]
\centering
\begin{tabular}{ |c|c|c|c|c| } 
\hline
Cryptography Library & Algorithm Families & Language & Compatible OSs & First Created\\
\hline
OpenSSL (libcrypto)\cite{libcrypto} & 9 & C & 28 & 1998\\
wolfSSL (wolfCrypt)\cite{wolfCrypt} & 6 & C & 26 & 2006\\
cryptlib\cite{cryptlib} & 6 & C & 37 & 1995\\
GPG (Libgcrypt)\cite{libgcrypt} & 11 & C & Unknown & 1999\\
\hline
\end{tabular}
\caption{Comparison of Cryptographic Libraries}
\label{tab:cryptolib}
\end{table}

From the previous table, it is apparent that libgcrypt supports the most algorithms from the comparison given in \cite{hashlibcomp}, however for cross compatibility, cryptlib boasts 37 supported operating systems. OpenSSL's libcrypto sits in the middle of the two, supporting nine hash algorithm families and 28 different operating systems. Additionally, libcrypto has been the default cryptography library distributed with most Linux, BSD and Windows operating systems, meaning it has received a large amount of support, and faced tight scrutiny by the likes of Microsoft. This made libcrypto the optimum library for use in this project. 

\section{Fault Tolerance}
In regards to fault tolerance, this project was extremely limited, as it ran as a high-level application on general operating systems, meaning the operating systems themselves provided no guarantees of  performance or reliability. With regards to fault tolerance during operation, the only reasonable measure was to ensure no malformed data could be propagated throughout the system. Such malicious data could cause the local \gls{stub}, or even worse, remote \gls{stub}s to crash, rendering the entire system non-functional whilst the malicious data is removed from each system. This measure was achieved by using the fail-early principle in all functions within the system. When each function is executed, specific checks take place, such as ensuring buffers are large enough to store specified data, and that the data provided is valid, and of the required type. Many of these checks are provided by the standard library within the C language, such as verifying the string representation of an \acrshort{IP} address is  correctly formatted when parsing to a binary representation of the network address. The vast majority of these functions return an integer to represent whether the function exited normally, or if it exited with an error, which was replicated in many of the functions provided by this application. Returning the exit status enables any calling functions to know that the function did not exit normally, which means the output of that function will contain incorrect data, and so the path of execution can no longer follow the normal path, but must instead fail early, and return to the top-level calling function.

In addition to the fail-early principle, each node maintains a log of all complete transactions that have taken place on that node. Once a node receives either an advertisement, or a new rule, it is logged immediately. This means that should the operating system fail, or the system suffers from an unrecoverable fault, the operating system can immediately restart the system (which can run as a daemon) which will then load all known hosts into memory, and rebuild the chain from the transaction log.\\\\

This section has provided a high-level explanation of how this project was implemented, along with the reasons particular technologies were used. Now a functional implementation has been created, the system can be tested.

\chapter{Testing} \label{test}
Testing the system required tests to be categorised into two types: local and network. Local tests consist of any functions which take place on the local node, such as \gls{hashing} of blocks and controlling network sockets. These local tests can be easily tested using unit tests. Network tests consist of protocol tests that can only be tested over a physical network. Network tests are much harder to strategically test an attempts to test these using unit tests would require careful synchronisation, such that when one node was testing it's send feature, another node would need to be ready to accept a message, for this reason networks tests did not use unit tests.

\section{Local Testing} \label{loctest}
As previously mentioned, local tests were carried out with unit tests. There are a number of unit test frameworks for C, which all offer very similar functionality, and for this reason the decision process will not be discussed here, however in the end the cmocka\cite{cmocka} framework was identified as the best framework for this project. All tests were carried out on six different devices, which contained different architectures, hardware, operating systems and distributions. Furthermore, four out of the five devices tested were low-power single board computers including Raspberry Pi's and Orange Pi's, two of which only had 512MB of memory, providing an additional test to check how demanding the system would be. The operating systems were chosen as they all have strong market shares in networking components and technologies, in addition to being freely available and supporting a wide range of hardware. A summary of these devices is given below.

\begin{table}[H]
\centering
\begin{tabular}{ |c|c|c|c|c| } 
\hline
Architecture & Network Hardware & Operating System & Distribution\\
\hline
Intel x86 & Intel & Linux 5.11.12 & Artix\\
Intel x86 & Realtek & Windows 10 & Home\\
ARMv7 & Allwinner & Linux 5.3.5 & Ubuntu\\
ARMv7 & Allwinner & Linux 5.10.12 & Armbian\\
ARMv7 & Broadcom & NetBSD 8.0 & N/A\\
ARMv8 & Broadcom & FreeBSD 13 & N/A\\
\hline
\end{tabular}
\caption{Devices used for Testing}
\label{tab:testdevices}
\end{table}

A summary of the tests used is provided below.

\begin{table}[H]
\centering
\begin{tabular}{ |c|c|c|c|c| } 
\hline
Name\\
\hline
Get block hash (invalid, buffer is null)\\
Get block hash (invalid, buffer too small)\\
Get block hash (invalid, block is null)\\
Get block hash (valid)\\
Get hash string (invalid, hash is null)\\
Get hash string (invalid, buffer too small)\\
Get hash string (invalid, buffer is null)\\
Get hash string (valid)\\
Initialise network stack (valid)\\
Clean up network stack (valid)\\
Send and receive message (valid)\\
Get Local IP Address (valid)\\
Load hosts from file (valid)\\
Add host (valid)\\
Initialise socket API (valid)\\
Clean up socket API (valid)\\
Create socket (valid)\\
Bind sending socket (valid)\\
Bind receiving socket (valid)\\
Bind socket (invalid, null socket)\\
Bind socket (invalid, port already in use)\\
Send and receive over socket (valid)\\
\hline
\end{tabular}
\caption{Unit Tests}
\label{tab:unittests}
\end{table}

\section{Network Testing}
In order to test the operation over the network, a physical network was created using a switch and all of the devices described in table \ref{tab:testdevices}. A diagram of this topology is pictured below. Due to the nature of this project, these network tests were carried out at various stages throughout the development processes. There was no formal agenda to these tests, instead a large number of scenarios were created using the pictured network. All of the tested scenarios were handled correctly, which included testing advertisements, both valid and invalid consensus messages and verifying if rules were successfully communicated between nodes.

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth,keepaspectratio]{networkmap}
\caption{The network layout used for testing} 
\label{fig:networkmap}
\end{figure}


\section{Attack Simulation and Performance Testing} \label{simu}
Following successful unit and network tests, an attack was simulated on the system to measure how long it took for a rule to be created, advertised, consensus gained and then transmit to all other nodes. The attack would be reported to the \gls{stub} of one node, and the local timestamp would be recorded at each step of the process. Ideally, timestamps would be collected at all nodes, however due to variations in clocks, synchronisations and architectures, the resulting data was inaccurate, and hence it was decided that timestamps would only be taken from the local node.

\begin{table}[H]
\centering
\begin{tabular}{ |c|c|c|c|c| } 
\hline
Stage & Time (s)\\
\hline
Received firewall rule via IPC & 1618330473.99529\\
Sent all consensus broadcasts & 1618330473.99558\\
Received all consensus acks & 1618330474.49588\\
Sent new firewall rule to all nodes & 1618330474.49599\\
New block added to chain & 1618330474.49631\\
\hline
\end{tabular}
\caption{Attack Simulation Results}
\label{tab:attack}
\end{table}

The times provided in the above table are given in seconds since the epoch. Running on a standard operating system, not designed for real-time, the entire transaction took place in 501.02 ms, and out of that duration, 500 ms is a hard-coded delay to wait for acknowledgements for the consensus. This indicates that with regards to processing time, only 1.02 ms is required to carry out the required calculations, \gls{hashing} and assembling the chain.

\section{Checking for Memory Leaks}
Not only is it essential that the system is functionally and logically correct, but it must also correctly utilise system resources. The most important of these resources is memory, in particular, the heap where numerous dynamic allocations are made throughout the lifetime of the \gls{stub}. As the system is designed to function for extended periods of time, it is essential that any memory allocated is correct freed back to the operating system otherwise the system would slowly begin consuming all memory on the system, leading to a crash.
The chosen way to test for memory leaks was to use the tool Valgrind \cite{valgrind}. Valgrind provides an extensive range of memory and thread checking tools along with profiling tools. For this test, the memory leak test was run with the \texttt{--leak-check=full} option enabled to provide a thorough check. In order to provide a fair and realistic test, a number of hosts on the network first advertised, and then several firewall transactions took place from different nodes. 

The test was carried out by connecting all six nodes to the system, followed by two firewall rule transactions. \\\\

This chapter has provided an overview of how the system will be tested. The next chapter will detail the results of these testing methods, along with a general evaluation of the success of the project

\chapter{Evaluation}

This chapter will detail the successful aspects of the project in addition to identifying where the project could have been improved. Additionally, the results from the previously detailed tests will be used to evaluate the effectiveness of the provided system and implementation.

\section{Project Results}

\subsection{Decentralised Distributed System Model}
The first output of this project is a new model for creating decentralised distributed systems. As discussed at the start of this publication, distributed systems are traditionally centralised systems, and those that are decentralised usually require a large amount of overhead to ensure consistency across the system. This project has produced a much more lightweight protocol, called the ACR (Advertisement, Consensus, Rule) protocol which enables quick transactions to be propagated throughout any network, with no requirements for specific hardware or network topology. The ACR protocol was designed as a high level abstraction for the underlying transaction stages, and acts as a very high level interface for additional implementations. This allows a huge amount of variation, for example any combination of advertisement, consensus and rule transaction methods can be used, which can then be further customised, for example by using different hash algorithms, or adding additional fields to the blocks.

The primary advantage of this model is speed, simplicity and redundancy, however encasing an entire protocol into just three message types vastly reduces the amount of control available, which means that this model currently does not have a method for nodes to catch up to a chain, instead it must simply start a new chain and is unable not obtain any previous knowledge within the system. There are a number of additional issues with the proposed implementation, the first of which is the propagation mechanism. Currently, each time a node receives a message from any other node, if that node is not the message's destination, it is forwarded to all known hosts. This creates an extremely high number of redundant packets on the network, which is exponential with regards to the number of hops permitted for each message. When the simulation in section \ref{simu} was analysed, over 16,000 messages were sent across the network for only five advertisements and two consensus-rule transactions. For smaller networks, this can be avoided by reducing the hop count to the minimum required to reach all nodes, however the problem only gets worse when applying this protocol to larger networks.

Security is another major flaw within the proposed implementation. While the ACR protocol does permit security, it is not discussed in this publication due to the difficulty of reliably securing transactions over \acrshort{UDP}. To implement security would require some form of key negotiation at the advertisement stage, however if a malicious node has gained access to the network, then it can easily intercept the negotiation, allowing it to decrypt any message involving that node. This would also introduce a large overhead in regards to computation, as each node would be required to store the keys of every other node, and as seen by the inefficiency of the message system, each node would be required to carry out a large volume of decryption and encryption.

\subsection{Firewall Blockchains}
The second output of this project is a new application of \gls{blockchain} to firewall rules. \Gls{blockchain} is a prominent technology used within decentralised cryptography for validating cryptocurrency transactions, but is yet to see many uses in cybersecurity. This project has explored one of many potential uses, by enabling nodes to share information about attacks in the form of firewall rules, which allow other nodes to quickly configure their security to protect against the coming attacks. To accommodate these new transactions, a new form of consensus mechanism had to be created in order to provide near real-time decisions across a vast network.

The proposed consensus mechanism, although it is some form of consensus, is not necessarily a secure nor trustworthy method. Traditionally, in \gls{blockchain}, transactions are not validated in real-time, and instead the hash is solved via a process called mining. Only once this hash has been mined, a process achieved by a number of high power \acrfull{GPU}s, is the transaction deemed as valid and appended onto the \gls{blockchain}. This consensus mechanism ensures the legitimacy of the block, whereas the proposed consensus method does not necessarily validate this property. Instead, the current consensus mechanism simply determines whether the sending node is up-to-date with the reset of the system, whereby if it's last block is the same as the majority of other nodes, the new block is deemed as valid, as the hashes will correctly match. This technique does mitigate the risks of a malicious node joining the network and immediately sending malicious firewall rules, however such a mechanism can easily be defeated by intercepting a genuine rule message, and using its hash to then validate its own block.

Similarly to the model mentioned above, the firewall \gls{blockchain} is also designed with flexibility. The examples shown in this project demonstrate how the chain is used to store traditional stateless rules, which either allow or block transactions based entirely off the \acrshort{IP} information of each packet. These rules could be easily modified to contain rules which are evaluated depending on the contents of each packet, or other control mechanisms such as a \acrfull{ACL}, which can be integrated into organisational security mechanisms.

\subsection{Proof of Concept}
The final output of this project is a proof of concept implementation of the system. This proof of concept is provided in the form of a C program which is written in such a way to be cross-compatible with the majority of UNIX and Windows operating systems. Measured on the primary development computer, this C program which acts as a \gls{stub} in the distributed system is 22.9 KB in size, which makes the system extremely portable (you could store 62 copies on a single floppy disk). This proof of concept is designed to run in the background (as a daemon) and receives communications via \acrshort{IPC} and over the network, and works extremely effectively as seem by the tests carried out. For sending messages to the system via \acrshort{IPC}, a small driver program was written in C, which was used to construct messages and then send then to the \gls{stub} in the relevant format.

In addition to communicating via \acrshort{IPC}, as the chosen communication channel is message queues and named pipes, interfaces can easily be built in other programming languages to relay messages to the \gls{stub}. Whilst it was established that this was possible early in the project, it wasn't until the end that a driver program was implemented in a different language. It was then decided that a Java wrapper would be created as Java is a widely used language, and also presents an additional challenge of sending messages out of the JVM and through the native \acrshort{IPC} mechanism. Whilst developing this it was discovered that nobody had yet created a library for passing messages from Java to a POSIX message queue, and hence a secondary project was created, called JPMQ \cite{jpmq}. Although the details will not be discussed here, JPMQ provides a method of interfacing with \acrshort{POSIX} message queues. The development of this Java based program reinforces the advantages previously mentioned of developing the program in C, as it allows nearly all higher languages to communicate via relevant wrappers and \acrshort{API}s.

\section{Evaluating the Development Process}
In regards to software engineering, this project has created a working, reliable piece of software which is cross compatible and has been extensively tested. With regards to the development methodology used, the waterfall method seemed like the most appropriate method, as the project was developed by a single person, and there would be no input from clients so there would be no substantial changes along the way. Using a method such as agile would vastly overcomplicate the development process, as if a particular element of the project was delayed, the rest of development would need to be restructured which would add unnecessary overhead to the project administration. This method worked very well for this project as at the start of the project there were a lot of new technologies and a number of hurdles to overcome, and using the waterfall method allowed each technology to be implemented one step at a time without concern for the other aspects of the project.

The original designs for the system were intentionally vague due to the project using unfamiliar technologies. Unfortunately this did lead to a number of oversights throughout the project, for instance although the rough outline of the protocol was designed upfront, there were a number of issues such as how routing would be carried out, and how exactly consensus would be negotiated. Ultimately however, the original timetable permitted sufficient time for researching and working on these additional issues, but they could have been avoided with more careful designing.

With regards to implementation, this project used a loose implementation of the \acrfull{TDD} methodology. The term 'loose' is used here as it was implemented alongside the previously mentioned waterfall method. \acrshort{TDD} was used to help keep the project on track, as if tests were not created up front, there was a large risk of feature creep, and the addition of unnecessary features into a system which is designed to be reliable is not a good idea. Unlike traditional \acrshort{TDD}, this project did not define all tests upfront, but instead tests were created prior to each stage / component of the system. The reason for this was due to the unfamiliarity with the libraries used, and so it seemed logical to create the tests once a strong understanding was grasped of that particular technology. This system worked well and ensured that tests were suitable and tailored to both the problem and the technologies used.

\section{Test Results}
The methodology for testing was described in detail in section \ref{test}, however this section provides a more detailed analysis of those results. 

The local tests all passed for the tested operating systems and architectures. The local tests confirmed that all of the tested hardware and operating systems supported the software, and that the software could correctly interact with other components on the \acrshort{OS}. It would be bewildering to show all test outputs here, so the tests for one particular operating system are provided below.

\begin{figure}[H]
\centering
\includegraphics[width=200px,keepaspectratio]{blockchain_test}
\caption{The output of the blockchain unit tests} 
\label{fig:blockchaintest}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=200px,keepaspectratio]{net_test}
\caption{The output of the network unit tests} 
\label{fig:nettest}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=200px,keepaspectratio]{socket_test}
\caption{The output of the socket unit tests} 
\label{fig:socktest}
\end{figure}

Unfortunately the number of tests that could be carried out locally was constricted by the networked nature of the system. Although these tests are limited, they did provide valuable information and guidance when implementing these functions, however their effectiveness began to decline as the system became more complex. As can be seen from the tables in \ref{loctest}, there were a large number of additional functions implemented but not tested, and this is where using both waterfall and \acrshort{TDD} began to lose effectiveness. Before starting development on a particular component, the tests were written up, however it became increasingly difficult to maintain both the tests and the functional code, which resulted in \acrshort{TDD} becoming a lower priority and functions were instead tested as they were implemented, which is why there is a lack of tests in the unit tests.

Additionally, as mentioned previously, the software underwent testing for memory leaks to ensure it was capable of operating without hogging system resources. The image below shows the output of Valgrind, indicating that there were a total of 43 heap allocations throughout the lifetime of the program, and that there were no allocated bytes still in use at the point of program termination. Additionally, Valgrind provides a convenient summary stating that \say{All heap blocks were freed - no leaks are possible}.

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth,keepaspectratio]{valgrind}
\caption{The output of Valgrind} 
\label{fig:valgrind}
\end{figure}

Valgrind is an effective tool and is well recognised for its accuracy and detailed output when a leak is found. It can therefore be trusted that the output pictured above is accurate, and that the software does not contain any memory leaks.\\\\

Now the system has been evaluated and the results of the testing process have been collected it is clear that the system operates correctly and a successful and functional proof of concept has been created.

\chapter{Conclusion}

This section will conclude the project by identifying whether the original aims and objectives were met, and suggesting future work to improve the proposed system.
    %\item Evaluate the effectiveness of existing distributed security mechanisms.
    %\item Investigate methods of establishing connections and synchronising computers within distributed systems.
    %\item Understand the structure of \gls{blockchain}s and adapt them for firewall transactions.
    %\item Implement and test relevant resilience, fault tolerance and security mechanisms.
    %\item Compare the use of decentralised security mechanisms.

\section{Original Aims and Objectives}
This project satisfied the original aim, creating a security model which comprises of protocols and data structures that utilises \gls{blockchain} in order to create a decentralised security mechanism that can be operated over a distributed system. However, it has not succeeded in meeting all of the proposed objectives.\\


\textbf{Objective 1} was partially met as initial research did provide background information with regards to existing distributed security mechanisms and their uses, however this literature has not drawn any evaluation in regard to their effectiveness. Unfortunately this objective was not met due a lack of publicly accessible information on these systems and due to time constraints.\\

\textbf{Objective 2} was met as initial research and existing knowledge allowed a number of possible methods of both connection establishment and synchronisation techniques to be investigated. As detailed it was decided that the best method of establishing connections was actually not to use any connection oriented protocols at all, and \acrshort{UDP} which is a connectionless protocol was identified as the best protocol for this project. As for synchronisation, this aspect became largely irrelevant as the implementation of \gls{blockchain} provided a mechanism for keeping all nodes up-to-date with the correct information.\\

\textbf{Objective 3} was met as a structure for encapsulating firewall transactions within \gls{blockchain} was designed and successfully implemented into the system.\\

\textbf{Objective 4} was partially met as additional research indicated that a number of fault tolerance mechanisms would not be suitable for this project. As the project runs on an underlying operating system, the amount of control the software has is not sufficient for traditional fault tolerance mechanisms. Instead, the software utilises a fail early design, such that should a situation arise that is unrecoverable, the system will simply ignore the malicious data, or if needed, terminate the program. Additionally, backups are created whenever a transaction takes place enabling the system to load its previous state should it crash or terminate.\\

\textbf{Objective 5} was not met as despite thorough research, no existing decentralised security mechanisms were found, which implies that this project could be the first publicly available implementation of such a system.

\section{Personal Development}
Throughout this project I have developed a number of skills and vastly expanded my knowledge of certain areas of computing. One of the most important skills I have developed is my research ability as before undertaking this project I had never carried out such thorough research nor analysed the literature I was reading in such depth. These skills will allow be to continue to both learn and scrutinise research in the future, and should I be the author of any research I feel much more confident in writing clear documents, with reputable references.

Developing this project in a low level language such as C has taught me a number of practises for developing reliable and correct software. At the beginning of the development, my enjoyment of writing C quickly became a chore as I was bombarded with segmentation faults and core dumps and not understanding why the software was behaving in particular ways. After hours spent debugging, I slowly learnt how making assumptions about how a computer may act is a crucial mistake, and quickly began ensuring all data was formatted to the exact specifications of the C language. After correcting my mistakes, I could now see how my code had let to unpredictable behaviour and now know how to avoid it.

In regards to technical knowledge, this project has required me to gain a thorough understanding of operating systems, distributed systems and \gls{blockchain}. I had some prior knowledge of operating systems however I was required to learn about entirely new aspects including \acrshort{IPC}, sockets and networking in general. Additionally, I learnt a number of lessons with regard to cross compatibility and learnt a number of quirks in regards to different operating systems and how they behave. I also only had a limited amount of knowledge regarding distributed systems, and throughout this project I have gained a thorough understanding of how they use \gls{stub}s to collaboratively establish \gls{middleware}, which permits transactions to exchange information across a network.

 Finally, I developed my understanding of \gls{blockchain}, and unlike before this project, \gls{blockchain} is no longer just a buzzword. I have learnt that \gls{blockchain} is not only useful in cryptocurrency, but has a number of additional uses including those discussed in this literature.

\section{Future Work}
There are a number of changes and most importantly improvements that can be made to this project. There are a wide range of minor changes which could include the structure of the blocks in the chain, or simply the \gls{hashing} algorithms used, however there are also some less trivial changes which are listed below:

\begin{itemize}
\item \textbf{Security} - Currently there is no security regarding encapsulating the protocol, and furthermore, the protocol itself does contain known vulnerabilities which are not desirable. Ideal future work would include securing the packets sent across the network, which could be achieved by using some kind of shared key across the entire network, however this would only prevent outside devices from snooping, and would still allow bad actors within the network to snoop. Alternatively, \acrshort{UDP} could be replaced with \acrshort{TCP} which would allow common security protocols such as Transport Layer Security (TLS) to be utilised, however this would add a large amount of overhead, hence reducing the speed at which messages can propagate.

\item \textbf{Message Efficiency} - Currently the protocol is hugely inefficient in regards to the number of messages transmitted across the network. The use of hops and the fact that each host relays any message it receives to all of its known hosts creates an exponential amount of messages on the network, which means that should the number of hosts reach a high enough level, the network essentially creates a Distributed Denial-of-Service (DDOS) attack, potentially causing devices to spend too much time processing messages instead of processing genuine traffic. The efficiency of messages could be vastly improved by integrating a more effective mechanism for providing redundancy.

\item \textbf{Programming Language} - The implementation provided in this project is written in C, however there are a number of alternatives that could offer much more resilience and tolerance to error. A number of these were considered but dismissed due to their immaturity. Whilst this is still true, upon reflection I have learnt that benefits such as Go's efficiency and Rust's memory safety could provide better safety and resiliency. Furthermore, these languages are both compiled which means they would be no less efficient that the C implementation, and could be much easily developed for, with less quirks than C. The only current barrier is that these languages do not currently support all of the operating system interfaces that C currently does, but an implementation could easily use different \acrshort{IPC} methods or networking interfaces to ensure compatibility.

\end{itemize}

\printglossaries

\bibliography{bib} 
\bibliographystyle{ieeetr}

\appendix

%\iffalse
\chapter{Framework Source Code}
\lstinputlisting[language=c,style=c,caption=main.c,basicstyle=\ttfamily\scriptsize]{../src/main.c}
\lstinputlisting[language=c,style=c,caption=blockchain.h,basicstyle=\ttfamily\scriptsize]{../src/blockchain.h}
\lstinputlisting[language=c,style=c,caption=blockchain.c,basicstyle=\ttfamily\scriptsize]{../src/blockchain.c}
\lstinputlisting[language=c,style=c,caption=firewall.h,basicstyle=\ttfamily\scriptsize]{../src/firewall.h}
\lstinputlisting[language=c,style=c,caption=firewall.c,basicstyle=\ttfamily\scriptsize]{../src/firewall.c}
\lstinputlisting[language=c,style=c,caption=ipc.h,basicstyle=\ttfamily\scriptsize]{../src/ipc.h}
\lstinputlisting[language=c,style=c,caption=ipc.c,basicstyle=\ttfamily\scriptsize]{../src/ipc.c}
\lstinputlisting[language=c,style=c,caption=net.h,basicstyle=\ttfamily\scriptsize]{../src/net.h}
\lstinputlisting[language=c,style=c,caption=net.c,basicstyle=\ttfamily\scriptsize]{../src/net.c}
\lstinputlisting[language=c,style=c,caption=socket.h,basicstyle=\ttfamily\scriptsize]{../src/socket.h}
\lstinputlisting[language=c,style=c,caption=socket.c,basicstyle=\ttfamily\scriptsize]{../src/socket.c}


\chapter{Client Program Source Code}
\lstinputlisting[language=c,style=c,caption=client.c,basicstyle=\ttfamily\scriptsize]{"../src/example\string_client/client.c"}

\chapter{Code and Framework Documentation}
\includepdf[pages=-]{../docs/latex/refman.pdf}



\end{document}